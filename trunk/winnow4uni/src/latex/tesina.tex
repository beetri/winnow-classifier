\documentclass[twocolumn]{article}
\usepackage{cite}
\usepackage{hyperref}



\begin{document}
\title{Question Classification and On-Line Alghoritms: Winnow Classifier}
\author{valerio \& fabio}
% Remove command to get current date 
\date{\today}
\maketitle

\begin{abstract}
questo lo scrivo alla fine! farò un brevissimo riassunto, niente di particolare.
Però tanto per anticipare quello di cui parliamo è la QC e l'implementazione fatta da noi è 
winnow, un algoritmo on-line.
...
\end{abstract}

\section{Introduction}
Con l'aumento della popolarit\'a e della diffusione del web, e conseguentemente con l'aumento 
dell'informazione testuale sul web, il processamento automatico di informazione testuale scritta in 
linguaggio naturale diviene sempre pi\'u importante.\cite{Zhalaing}. A tale fine si usano tecniche di 
Information Retrieval, che sono alla base degli attuali motori di ricerca web: quando un utente ha 
un information need, sottomette una query al motore di ricerca, che produrr\'a 
come output un insieme di documenti che con buona probabilit\'a dovrebbero contenere l'informazione 
necessaria all'utente.

\subsection{Question Answering}
Il Question Answering \'e una variazione dell'information retrieval (IR): 
mentre l'IR \'e orientata ai documenti, il QA ricerca specifiche informazioni all'interno dei documenti 
cercando di fornire direttamente la risposta all'information need dell'utente \cite{WeiLi}. Ed \'e quindi 
un compito pi\'u difficile rispetto all'IR, poich\'e fornire una risposta precisa e concisa \'e pi\'u complesso 
di produrre un intero documento di testo probabilmente molto lungo.
Un sistema di QA \'e generalmente costituito da 4 moduli:
\begin{description}
	\item[Question Classifier] ha il compito di classificare la domanda in categorie 
	prestabilite.
	\item[Search Engine] basando sulla categoria prodotta dal modulo precedente, ricerca 
	i documenti che hanno probabilit\'a pi\'u alta di contenere la risposta.
	\item[Text Filter] individua le parti di testo all'interno dei documenti, che potrebbero 
	contenere la risposta.
	\item[Answer Extractor] deduce la risposta dalle parti di testo individuate dal modulo 
	precedente, e le presenta in linguaggio naturale all'utente del sistema.
\end{description}

\subsection{Question Classification}
Il processo di QC ha quindi il compito di assegnare particolari categorie alle domande, basandosi sul tipo 
di risposta che la domanda rappresenta. Per classificare le domande, o pi\'u in generale del test, 
\'e necessario prendere in considerazione due aspetti basilari \cite{brown}:
\begin{itemize}
	\item i tipi delle risposte, le categorie
	\item un insieme di regole di classificazione
\end{itemize}
 
\subsubsection{Answer Types}
Definire un proprio insieme di categorie da utilizzare nella question classification \'e una 
delle soluzioni, ma non sempre la migliore. \'E possibile utilizzare dei sistemi di categorie gi\'a usati in precedenza. 
Il riuso di tali sistemi, oltre a far risparmiare una notevole quantità di tempo, è decisamente utile per 
comparare i propri risultati con altri ottenuti in precedenza. 

I primi sistemi di question classification utilizzavano una suddivisione in un piccolo numero 
di categorie: sei o sette. Recentemente i ricercatori si sono interessati nella costruzione 
di categorie migliori: i sistemi attuali solitamente prevedono 
una divisione in 6-7 categorie a grana grossa, e una successiva suddivisione di ogni categoria in altrettante 
di dettaglio. Tra i tipi di risposte pi\'u famoss troviamo:
\begin{itemize}
	\item Xin Li e Dan Roth, che propongono una suddivisione in 50 sotto categorie e 6 macro categorie \cite{XinLi}:	
	\begin{itemize}
		\item Abbreviation
		\item Entity
		\item Description
		\item Human
		\item Location
		\item Numerical Value.
	\end{itemize}
	\item Webclopedia, che usa oltre 140 tipi di risposte, anche chiamati qtargets. Questi sono raggruppati in 
	8 macro categorie \cite{gerber}:	
	\begin{enumerate}
		\item relational qtargets
		\item abstract qtargets
		\item semantic qtargets
		\item syntactic qtargets
		\item role qtargets
		\item slot qtargets
		\item lexical qtargets
		\item combinations of other qtargets.
	\end{enumerate}
\end{itemize}

\subsubsection{Classification Strategies}
Esistono diverse strategie/regole di classificazione:

\paragraph{Regular expression and hand-written grammar rules} 
sono le prime tecniche utilizzate per la 
question classification, ma hanno dei grossi limiti, sebbene abbiano avuto successo \cite{brown}:
\begin{itemize}
	\item in primo luogo tali tecniche richiedono molto tempo, poich\'e sono scritte a mano
	\item in secondo luogo sono poco evolvibili, con il cambiare delle categorie
	\item se cambiamo l'insieme delle categorie, tutte le regole devono essere riscritte
	\item infine sono molto difficili da scrivere, soprattutto quando si usano tante categorie 
	a grana fine.
\end{itemize}
Non \'e un caso, infatti, che tali sistemi utilizzino meno di dieci categorie.

\paragraph{Machine Learning Algorithm}
L'algoritmo pi\'u utilizzato in questo campo \'e SVM, support vector machine. Un'altra architettura 
molto usata \'e SNoW \cite{XinLi}. La precision di tali algoritmi, utlizzando solo le parole delle 
domande, si aggira sul 50\%. Ma si possono utilizzare molte altre feature oltre alle 
semplici parole, come ad esempio: le named entity, head chunk etc.

\paragraph{Language Modleling} 
Un altro metodo, sempre probabilistico come il machine learning, \'e il language modeling.
Un modello di linguaggio \'e creato per ogni classe, a partire da tutte le domande 
appartenenti a quella classe. Dato uno di questi modelli, il nostro obiettivo \'e 
scoprire la probabilit\'a con cui la question sia generata da tale modello. Anche in questo caso 
si possono utilizzare altri insiemi di feature oltre alle semplici parole, come le named entity \cite{pinto}.


\section{Our Scope: Machine Learning}
Sebbene sia possibile create classificatori con regole euristiche costruite ad hoc, tale approccio 
richiede un'enorme quantit\'a di tempo e di noioso lavoro. Per di più un approccio troppo specifico sarebbe poco flessibile ai cambiamenti che si trovano nel dominio di interesse.
Utilizzando tecniche di machine learning \'e al contrario \'e possibile costruire classificatori che abbiano alte performance e che riescano a gestire migliaia di feature. Oltretutto tale 
approccio \'e pi\'u flessibile e si adatta facilmente a nuove categorie \cite{Zhang}. Ed \'e questo 
l'approccio che intendiamo usare per il nostro classificatore.
I classificatori si disinguono in due grosse macrocategorie:
\begin{enumerate}
	\item OffLine;
	\item OnLine.
\end{enumerate}
le due categorie si distinguono soprattuto per prestazioni, tempo di addestramento, flessibilità e conseguentemente per algoritmo.

Un classificatore OffLine deve essere addestrato da un insieme di input (insieme di training) e solo dopo questa operazione può essere utilizzato per classificare ma non puo' più in essere riaddestrato se non ricompiendo un addestramento completo. Al contrario un algoritmo OnLine per cos\'i dire impara sul campo e durante l'addestramento può comunque essere interrogato, questo consente all'addestratore di valutare in continuazione come sta procedendo il lavoro di inferenza del dominio da parte del calssificatore.
All'apparenza un classificatore OnLine offre pi\'u vantaggi ma come spesso accade ai ``pro'' vanno sommati dei ``contro'', che in questo caso ricadono sulle prestazioni del classificatore; un classificatore OnLine \'e tipicamente peggiore di un classificatore OffLine.

\subsection{On-Line Algorithm}
abbiamo scelto on-line algoritmo perchè...

\subsection{Winnow}
in particolare usiamo winnow...

alcune citazione: le ho scritte per non scordarmele!

"winnow \'e adatto in teoria per problemi con molti attributi irrilevanti" \cite{Zhang}

"winnow impara linearmente con il numero di feature rilevanti, e solo logaritmicamente con il numero totale di feature. questa propriet\'a sembra cruciale in problemi nei quali il numero di feature potenziali \'e vasto 
ma solo poche sono rilevanti" \cite{snow}

\section{Pre-Processing - Feature Extraction}

\section{Experimental Set-Up}

\section{Experimental Result}
table table table 

\section{Conclusion}

\bibliography{tesina}
\bibliographystyle{plain}

\end{document}